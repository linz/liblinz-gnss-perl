#!/usr/bin/perl 

eval 'exec /usr/bin/perl  -S $0 ${1+"$@"}'
    if 0; # not running under some shell

=head1 gnss_ftp_mirror

Simple ftp mirror script to recursely mirror files from a remote ftp site 
to a local directory.  

The script is designed to interrogate a GNSS archive type file system with 
directories and files named after year, day, station code etc.  

The configuration file defines the structure of the file name and path in
terms of these components.  As the files are downloaded they can be renamed
using these fields.  

The script looks for a range of files based on their age in days (actually
the age of the data, not the file).  For example it can download files 
with dates matching the last 30 days.

=head2 Synopsis:

 gnss_ftp_mirror.pl [options] config_file [item=value ...]

The parameters are the name of a configuration, and a set of configuration
values which override the values in the configuration file.

Options are:

=over

=item  -v            

Verbose mode - lists information about downloads etc

=item  -V            

More verbose mode - additional information only messages

=item -s ###        

Specify the start date for downloads as days before the current date.  eg -s 30
or in a GNSS date format eg 2014-050.

=item -e ###        

Specify the end date for downloads as days before the current date.  eg -s 30
or in a GNSS date format eg 2014-050.

=item -p ##

Specifies a pause in seconds between successive downloads.  This is to be kind
to the server!  Default is 1 second unless defined otherwise in the configuration
file

=item -r ##

Specifies the maximum runtime for in minutes.  Downloads will be aborted after this 
time.

=item -i

Ignore file size. If present then all matching files are downloaded.  
Otherwise files will not be downloaded if there is already an existing file
of the same size.

=item -c

Print an example configuration file

=back

=cut

use strict;
use Getopt::Std;
use URI;
use Net::FTP;
use Cwd qw(abs_path getcwd);
use File::Path;
use File::Copy;
use File::Temp qw(tempdir);
use Time::HiRes;
use Config::General;
use Data::Dumper;
use POSIX qw/strftime/;
use LINZ::GNSS::Config;
use LINZ::GNSS::Time qw/parse_gnss_date datetime_seconds seconds_yearday time_elements seconds_ymdhms $SECS_PER_DAY/;

my $syntax=<<EOD;

Syntax: gnss_ftp_mirror.pl [-b|-B logfile] [options] config_file [item=value ...]

Options are:
   -n            List downloaded files
   -v            Verbose mode
   -V            Even more verbose
   -s ###        Start date to download (days before now)
   -e ###        End date to download (days before now)
   -p ##         Reset pause between downloads
   -r ###        Maximum run time in minutes
   -i            Ignore file size - download all matching files
   -f            Ignore recent downloads - download anyway
   -c            Print an example configuration file

EOD

#=====================================================================

my @months=('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec');
my @umonths=();
my @ccmonths=();
my @fullmonths=('january','february','march','april','may','june',
                'july','august','september','october','november','december');
my @ufmonths=();
my @cfmonths=();

foreach my $mon (@months) 
{
    push(@umonths,uc($mon));
    my $ccmon=$mon;
    substr($ccmon,0,1)=uc(substr($ccmon,0,1));
    push(@ccmonths,$ccmon);
}

foreach my $mon (@fullmonths) 
{
    push(@ufmonths,uc($mon));
    my $ccmon=$mon;
    substr($ccmon,0,1)=uc(substr($ccmon,0,1));
    push(@cfmonths,$ccmon);
}

my %patterns=(
    'yyyy' => '\d\d\d\d',
    'yy' =>   '\d\d',
    'hh' =>   '([01]\d|2[0-3])',
    'h' => '[a-x]',
    'H' => '[A-X]',
    'mm' =>   '(0[1-9]|1[0-2])',
    'mmm' =>  '('.join('|',@months).')',
    'Mmm' =>  '('.join('|',@ccmonths).')',
    'MMM' =>  '('.join('|',@umonths).')',
    'dd'  =>  '[0-3]\d',
    'ddd' =>  '[0-3]\d\d',
    'code' => '[a-z0-9]{4}',
    'CODE' => '[A-Z0-9]{4}',
    'Code' => '[A-Za-z0-9]{4}',
);

# Convert a time duration to seconds. Format is a number
# followed optionally by s,m,h,d for seconds, hours, minutes,
# days.  Default is minutes.

my %timeunitconv=(
    's' => 1,
    'm' => 60,
    'h' => 60*60,
    'd' => 60*60*24,
);

my $timespanre=qr/^\s*(\d+(?:\.\d*)?)\s*((?:s(?:econds?)?|m(?:inutes?)?|h(?:ours?)?|d(?:ays?)?)?)\s*$/;

sub timeToSeconds
{
    my($spanstr)=@_;
    $spanstr=lc($spanstr);
    return 0 if $spanstr !~ $timespanre;
    my $seconds=$1;
    my $units=substr($2 || 'm',0,1);
    $seconds *= $timeunitconv{$units};
    return $seconds;
}

#=================================================================
# Get options
my %opts;
getopts('gVvfncis:e:p:r:',\%opts);

if( $opts{c} )
{
    printExampleConfig();
    exit();
}

my $verbose=$opts{g} ? 3 : $opts{V} ? 2 : $opts{v} ? 1 : 0;
my $listfiles=$opts{n};
my $ignoresize=$opts{i};
my $forcedownload=$opts{f};
$verbose=3 if $ENV{LINZGNSS_DEBUG} eq 'debug';
STDOUT->autoflush(1);
STDERR->autoflush(1);

@ARGV >= 1 || die $syntax;

my %argconfig=();
my $conffile;
foreach my $arg (@ARGV)
{
    if($arg =~ /^(\w+)\=(.*)/)
    {
        $argconfig{lc($1)} = $2;
    }
    elsif( ! $conffile )
    {
        $conffile=$arg;
    }
    else
    {
        die "Invalid configuration argument $arg: should be xxx=yyy\n";
    }
}
die "Configuration file not defined\n" if ! $conffile;
die "Cannot find config file $conffile\n" if ! -f $conffile;

my $confdir=abs_path($conffile);
$confdir =~ s/[^\\\/]*$//;
$confdir =~ s/[\\\/]$//;
$confdir = '.' if $confdir eq '';

my %config=Config::General->new(
    -ConfigFile=>$conffile,
    -LowerCaseNames=>1,
    -UseApacheInclude=>1,
    -IncludeRelative=>1 )->getall();

foreach my $k (keys %argconfig)
{
    $config{$k}=$argconfig{$k};
}

$config{configdir} = $confdir;
$config{configfile} = $conffile;

# Expand references in configuration

my %unresolved=();
foreach my $k (keys(%config))
{
    my $v=$config{$k};
    my $maxiterations=10;
    while( $maxiterations > 0 )
    {
        my $v0=$v;
        $v =~ s/(\{(\w+)\})/exists $config{lc($2)} ? $config{lc($2)} : $1/eg;
        $v =~ s/(\{ENV\:(\w+)\})/exists $ENV{$2} ? $ENV{$2} : $1/eg;
        $v =~ s/(\{(\w+)\})/! exists $patterns{$2} && exists $ENV{$2} ? $ENV{$2} : $1/eg;
        last if $v eq $v0;
    }
    foreach my $var ($v =~ /\{((?:ENV\:)\w+)\}/g)
    {
        $unresolved{$var}=1 if ! exists $patterns{$var};
    }
    $config{$k}=$v;
}
if( %unresolved )
{
    my $badvar=join(' ',sort keys %unresolved);
    die "The following configuration items are undefined: $badvar\n";
}

my $bucketname=$config{s3_bucket};
my $bucketprefix;
my $bucket;
my $localdir;
my $localsrc;
require LINZ::GNSS::Config;
my @args=(
    "s3_bucket=".$bucketname,
    "s3_prefix=".$config{s3_prefix},
    "s3_aws_parameters=".$config{s3_aws_parameters},
    "s3_aws_client=".$config{aws_client},
    "s3_debug_aws=".($verbose > 1 ? 1 : 0),
    "logsettings=".($verbose > 1 ? 'DEBUG' : ($verbose > 0 ? 'INFO' : 'FATAL'))
);
my $cfg=new LINZ::GNSS::Config($conffile,@args);
$cfg->initLogger();
if( $bucketname )
{
    require LINZ::GNSS::AwsS3Bucket;
    $bucket = LINZ::GNSS::AwsS3Bucket->new(config=>$cfg);
    $localsrc='temporary working directory';
    $localdir=tempdir(CLEANUP=>1)
}
else
{
    $localsrc = $config{localbasedirectory};
    $localdir = $localsrc;
    $localdir =~ s/^\~(\/.*)?$/$confdir$1/;
    die "LocalBaseDirectory $localsrc is not a directory\n" if ! -d $localdir;
}

my $localpath=abs_path($localdir);
my $startdir=getcwd;
chdir($localpath);

undef $opts{s} if $opts{s} eq 'default';
undef $opts{e} if $opts{e} eq 'default';
my $startage=$opts{s} // $config{startage};
my $endage=$opts{e} // $config{endage};

$config{maxruntime} = ($opts{r}+0) if $opts{r};
$config{pause} = $opts{p} if exists $opts{p};
$config{verbose} = $verbose if $verbose;

my $codes=$config{codes};
$codes = join(' ',@$codes) if ref($codes) eq 'ARRAY';
$codes = join(' ',keys %$codes) if ref($codes) eq 'HASH';
my $validcodes={};
my $allcodes=0;
foreach my $c (split(' ',$codes))
{
    $allcodes=1 if $c eq '*';
    $validcodes->{uc($c)} = 1;
}
$allcodes = 1 if ! %$validcodes;


my $notcodes=$config{notcodes};
$notcodes = join(' ',@$notcodes) if ref($notcodes) eq 'ARRAY';
$notcodes = join(' ',keys %$notcodes) if ref($notcodes) eq 'HASH';
my $invalidcodes={};
foreach my $c (split(' ',$notcodes))
{
    $invalidcodes->{uc($c)} = 1;
}

my $remotedir=$config{remotedir};
my $remotefilere=$config{remotefilere};
my $targetpath=$config{targetpath};
my $markerpath=$config{markerpath};
my $commandshell=$config{postdownloadcommandshell};
my $postdownloadcommand=$config{postdownloadcommand};
my $statusfile=$config{statusfile};
my $mintimesincerun=$config{mintimesincelastrun};
my $dochdir=$config{postdownloadcommandchdir};
$dochdir=0 if $dochdir =~ /(no|false)/i;

my $startdate=$startage =~ /^\d+$/ ? "now-$startage" : $startage;
$startdate=parse_gnss_date($startdate);
my $enddate=$endage =~ /^\d+$/ ? "now-$endage" : $endage;
$enddate=parse_gnss_date($enddate);

my $maxruntime=timeToSeconds($config{maxruntime});
my $jobexpirytime = $maxruntime > 0 ? time()+$maxruntime*60 : 0;

my $mintimesincesuccess=0;
my $mintimesincefail=0;
if( $mintimesincerun )
{
    my($minsucc,$minfail)=split(' ',$mintimesincerun);
    $minfail=$minsucc if $minfail eq '';
    $mintimesincesuccess=timeToSeconds($minsucc);
    $mintimesincefail=timeToSeconds($minfail);
}

my $ftp;
my $remoteuri=$config{remoteuri};
if( $remoteuri =~ /^smb\:/ )
{
    $ftp=new SmbConnection( %config );
}
elsif( $remoteuri =~ /^file\:/ )
{
    $ftp=new FileConnection(%config);
}
elsif( $remoteuri =~ /^https?\:/ )
{
    $ftp=new HttpConnection(%config);
}
else
{
    $ftp=new FtpConnection( %config );
}

if( $verbose )
{
    print "------------------------------------------\n";
    print  "Mirror GNSS data       ",strftime("%Y:%m:%d %H:%M:%S",localtime),"\n"; 
    print  "Configuration:         $conffile\n";
    printf "Remote host:           %s\n",$ftp->host;
    printf "Remote user:           %s\n",$ftp->user;
    printf "Remote base dir:       %s\n",$ftp->basedir;
    print  "Remote directory:      $remotedir\n";
    print  "Remote file RE:        $remotefilere\n";
    print  "Local base directory:  $localsrc\n" if ! $bucketname;
    print  "S3 bucket:             $bucketname\n" if $bucketname;
    print  "S3 prefix:             $bucketprefix\n" if $bucketprefix;
    print  "Target file path:      $targetpath\n";
    print  "Marker file path:      $markerpath\n";
    printf "Change dir for pdc   : %s\n",$dochdir ? 'yes' : 'no';
    printf "Start date:            %04d:%03d\n",seconds_yearday($startdate);
    printf "End date:              %04d:%03d\n",seconds_yearday($enddate);
    if( $maxruntime > 0 )
    {
        printf "Max run time:     %.1f minutes\n",$maxruntime;
    }
    if( $allcodes )
    {
        print "Downloading:      all codes\n";
    }
    else
    {
        printf "Downloading:      %d codes\n",scalar(keys %$validcodes);
    }
    if( %$invalidcodes )
    {
        printf "Discarding:       %d codes\n",scalar(keys %$invalidcodes);
    }
    printf "FTP timeout:     %s\n",$ftp->timeout;
    if( $mintimesincesuccess || $mintimesincefail )
    {
        printf "Min time since last successful run: %.1f minutes\n",$mintimesincesuccess/60;
        printf "Min time since last failed run:     %.1f minutes\n",$mintimesincefail/60;
    }
    print  "Post download shell    $commandshell\n" if $commandshell;
    print  "Post download command: $postdownloadcommand\n";
}

# Test status file

my $successfile=$statusfile.'.success' if $statusfile;
my $failfile=$statusfile.'.fail' if $statusfile;

if( $statusfile )
{
    my $statusdir=$statusfile;
    $statusdir =~ s/[\\\/][^\\\/]*//;
    File::Path::make_path($statusdir) if $statusdir ne '';
    if( (-e $successfile && $mintimesincesuccess > $SECS_PER_DAY*(-M $successfile) )
     || (-e $failfile && $mintimesincefail > $SECS_PER_DAY*(-M $failfile) ) )
    {
        if( ! $forcedownload )
        {
            if( $verbose )
            {
                print "Skipping download as already done recently\n";
            }
            exit;
        }
    }
    # Get rid of old status files, create a fail file.  Replace
    # with success file if complete successfully.
    unlink($successfile);
    unlink($failfile);
    open(my $ffh, ">$failfile") || die "Cannot create status file $failfile\n";
    close($ffh);
}

# Ensure outputs are flushed to make it easy to monitor progress..
select(STDERR);
$|=1;
select(STDOUT);
$|=1;


$postdownloadcommand =~ s/(^|\s)\~\//$1.$confdir.'\/'/eg;

# @valid_dates is a list of possible date options that can be matched against fields directory/filenames.
# This is the starting point for filtering out the candidate files.

my @valid_dates=();
for( my $i = $startdate; $i <= $enddate; $i += $SECS_PER_DAY )
{
    # Allow offset of +1 day (N) or -1 day (P)
    my $filter={};
    foreach my $suffix ('','N','P')
    {
        my $offset = $suffix eq 'N' ? 1 : $suffix eq 'P' ? -1 : 0;
        my($yy,$mm,$dd)=(seconds_ymdhms($i+$offset*$SECS_PER_DAY));
        my($yy2,$skip,$ddd)=(time_elements($i+$offset*$SECS_PER_DAY));
        $filter->{'yyyy'.$suffix}=sprintf("%04d",$yy);
        $filter->{'yy'.$suffix}=sprintf("%02d",$yy%100);
        $filter->{'mm'.$suffix}=sprintf("%02d",$mm);
        $filter->{'ddd'.$suffix}=sprintf("%03d",$ddd);
        $filter->{'dd'.$suffix}=sprintf("%02d",$dd);
        $filter->{'mmm'.$suffix}=$months[$mm-1];
        $filter->{'MMM'.$suffix}=$umonths[$mm-1];
        $filter->{'Mmm'.$suffix}=$ccmonths[$mm-1];
        $filter->{'mmmm'.$suffix}=$fullmonths[$mm-1];
        $filter->{'MMMM'.$suffix}=$ufmonths[$mm-1];
        $filter->{'Mmmm'.$suffix}=$cfmonths[$mm-1];
    };
    push(@valid_dates,$filter);
}

# @dirparts is an array of components of the remote file path.  Each in turn
# is used to filter down the valid options before passing on to the next directory.
    
# Allow offset of +1 day (N) or -1 day (P)

my @dirparts;
foreach my $p ( split(/\//,$remotedir),$remotefilere)
{
    next if $p eq '';
    $p =~ s/\./\\./g;
    $p =~ s/\?/./g;
    $p =~ s/\*/.*/g;
    $p =~ s/\(\.\<(\w+)\>/(?<$1>/g;
    $p =~ s/(\{(\w+?)([+-]?1)?\})/
             exists $patterns{$2} ?
                '(?<'.$2.($3 eq '-1' ? 'P' : $3 eq '' ? '' : 'N' ).'>'.$patterns{$2}.')' :
                $1
                /exg;
    $p = '^'.$p.'$';

    my @fields=( $p =~ /\(\?\<(\w+)\>/g );
    printf("Directory level: Re /%s/: fields %s\n",$p,join(", ",@fields)) if $verbose > 2;
    push( @dirparts, { re=>qr/$p/, fields=>\@fields });
}

downloadDir( $ftp, $ftp->basedir, \@valid_dates, \@dirparts );
$ftp->quit();

if( $statusfile )
{
    unlink($failfile);
    open(my $ffh, ">$successfile") || die "Cannot create status file $successfile\n";
    close($successfile);
}

if( $verbose )
{
    print "\nFinished ",strftime("%Y:%m:%d %H:%M:%S",localtime),"\n"; 
    print "------------------------------------------\n";
}

#  filteredOptions:
#
#  $options is an array of currently valid options.  Each is a hash with a set of keys and values that match
#  $dirname is the name to filter the list against
#  $dirpart is the defines the structure of $dirname as a regular expression with named capture groups and a list of 
#     capture group names (fields)
#
#  Each currently valid option is tested against the name.  If all the fields in the name match currently existing
#  value in the option then it passes. Options that pass have any other fields in the name added to them.
#  
#  The field "code" is treated specially and is additionally matched against valid codes
#  The fields "h" and "hh" are handled to provide alternative representations of hour

sub filteredOptions
{
    my($options,$dirname,$dirpart) = @_;
    my @options=();
    my $fields=$dirpart->{fields};
    my $re=$dirpart->{re};
    my %fieldvalues=();
    return [] if $dirname !~ /$re/;
    my $code;
    foreach my $f (@$fields)
    {
        $fieldvalues{$f}=$+{$f};
        if(lc($f) eq 'code')
        {
            $fieldvalues{CODE}=uc($fieldvalues{$f});
            $fieldvalues{code}=lc($fieldvalues{$f});
            $fieldvalues{Code}=$fieldvalues{$f};
            $code=$fieldvalues{CODE};
        }
        elsif( lc($f) eq 'h' )
        {
            $fieldvalues{H}=uc($fieldvalues{$f});
            $fieldvalues{h}=lc($fieldvalues{$f});
            $fieldvalues{hh}=sprintf("%02d",ord($fieldvalues{h})-ord('a'));
        }
        elsif( lc($f) eq 'hh' )
        {
            my $hour=int($fieldvalues{$f});
            return [] if $hour < 0 || $hour > 23;
            $fieldvalues{h}=chr(ord('a')+$hour);
            $fieldvalues{H}=chr(ord('A')+$hour);
        }
    }

    return [] if ($code ne '' && ! $allcodes && ! $validcodes->{$code}) || $invalidcodes->{$code};

    my @matches=();

    foreach my $opt (@$options)
    {
        my $ok=1;
        foreach my $k (@$fields)
        {
            next if (! exists $opt->{$k}) || ($opt->{$k} eq $fieldvalues{$k});
            $ok = 0;
            last;
        }
        next if ! $ok;
        my %match=%$opt;
        while ( my ($k,$v) = each %fieldvalues ) { $match{$k}=$v; }
        push( @matches, \%match );
    }
    return \@matches;
}

sub expandTarget
{
    my ($opts,$file,$template,$variable,$location)=@_;
    my $result='';
    foreach my $opt (@$opts)
    {
        $opt->{filename} = $file;
        my $value=$template;
        $value =~ s/\{(\w+)\}/$opt->{$1}/eg;
        if( $value =~ /\{\w+\}/ )
        {
            print STDERR "** Unresolved $variable name $value for $location\n";
            return;
        }
        if( $result && $value ne $result )
        {
            print STDERR "** Ambiguous $variable for $location ($result,$value)\n";
            return;
        }
        $result = $value;
    }
return $result;
}

sub downloadDir
{
    my( $ftp, $dirname, $options, $dirparts ) = @_;
    return if $jobexpirytime && time > $jobexpirytime;
    print "Processing $dirname\n" if $verbose;
    if( ! $ftp->cwd($dirname) )
    {
        print STDERR "** Cannot access remote directory $dirname\n";
        return;
    }
    my ($dirs, $files) = $ftp->dirList();
    #print Data::Dumper->Dump([$options],['options']) if $verbose > 2;
    my @parts=@$dirparts;
    my $dirpart=shift(@parts);

    # If we are not at the list part of $dirparts, then we are matching against directories.
    # Recursively call this routine for valid directories.

    my $expired=0;
    if( @parts )
    {
        return if ! ref $dirs;
        foreach my $dir (@$dirs)
        {
            $expired=1;
            last if $jobexpirytime && time > $jobexpirytime;
            $expired=0;
            my $opts=filteredOptions($options,$dir,$dirpart);
            next if ! @$opts;
            downloadDir( $ftp, "$dirname/$dir", $opts, \@parts );
        }
        print STDERR "** Job terminated - maximum run time expired\n" if $expired;
        return;
    }

    # Otherwise we are matching against files for downloading, so 
    # try each one in turn

    return if ! ref $files;
    my $nfiles=0;
    # Ensure the target directory exists.. 
    my $startdir=getcwd();
    if( ! -d $localpath )
    {
        File::Path::make_path($localpath);
        cwd($localpath);
    }   
    # print Data::Dumper->Dump([$options],['options']) if $verbose > 2;     
    foreach my $file (sort keys %$files)
    {
        $expired=1;
        last if $jobexpirytime && time > $jobexpirytime;
        $expired=0;
        # Does it match the current filtered options
        my $opts=filteredOptions($options,$file,$dirpart);
        # print Data::Dumper->Dump([$file,$opts],['filename','opts']) if $verbose > 2;     
        next if ! @$opts;

        # Build the target name. There may be more than one filtered option
        # remaining, so make sure that if so they uniquely define a target name.
        # If not then fail the download.

        my $size=$files->{$file}->{size};

        my $target=expandTarget($opts,$file,$targetpath,'target file name',"$dirname/$file");
        my $marker=expandTarget($opts,$file,$markerpath,'marker file name',"$dirname/$file");
        my $command=expandTarget($opts,$file,$postdownloadcommand,'marker file name',"$dirname/$file");

        next if ! $target;

        my $available=0;
        my $tgtpath=$target;
        my $tgtname=$target;
        $tgtpath =~ s/[^\\\/]*$//;
        $tgtpath =~ s/[\\\/]$//;
        $tgtname =~ s/.*[\\\/]//;
        if( ! -d $tgtpath && ! File::Path::make_path($tgtpath) )
        {
            print STDERR "** Cannot create target directory at $tgtpath\n";
            next;
        }

        if( $bucket )
        {
            my $filestat=$bucket->fileStats($target);
            if( $filestat )
            {
                my $bsize=$filestat->{size};
                $available=$ignoresize || $bsize == $size;
                print "Reloading $tgtname ($bsize != $size)\n" if $verbose && ! $available;
            }
            # If not available try and get the marker file 
            if( ! $available && $marker )
            {
                $bucket->getFile($marker,$marker);
            }
        }

        # Now try and download the file
        elsif( -e $target )
        {
            if( ! -f $target )
            {
                print STDERR "** Cannot create file at $target - something is already there\n";
                next;
            }
            # Check the size - if it matches then assume the file is up to date.
            $available=$ignoresize || -s $target == $size;
        }
        if( $available )
        {
            print "$target is already downloaded and of the correct size\n" if $verbose > 1;
            next;
        }

        if( $marker && -f $marker )
        {
            my $markersize=$size;
            if( ! $ignoresize )
            {
                $markersize=0;
                if( open(my $mf, "<$marker") )
                {
                    $markersize=<$mf>+0;
                    close($mf);
                }
            }
            if( $size == $markersize )
            {
                print "$target marker file present and shows correct size\n" if $verbose > 1;
                next;
            }
        }

        # Download to a temporary file first to ensure failed 
        # downloads don't generate incomplete files.

        $nfiles++;
        my $tmp=$tgtpath.'/.download.'.$tgtname.'.tmp';
        unlink($tmp);

        if( ! $ftp->get($file,$tmp) )
        {
            print STDERR "** Failed to download $dirname/$file\n";
            # print STDERR $ftp->message,"\n";
            unlink($tmp);
        }
        elsif( ! move($tmp,$target) )
        {
            print STDERR "** Failed to overwrite $target\n";
            unlink($tmp);
        }
        else
        {
            print "Successfully downloaded $target\n" if $verbose;
            print "$target\n" if $listfiles;
            if( $command && $commandshell )
            {
                my $cwd=getcwd;
                chdir($tgtpath) if $dochdir;
                print "Running postdownload script with $commandshell\n" if $verbose;
                print "Script:\n$command\n" if $verbose > 1;
                eval
                {
                    open(my $shell, "| $commandshell" ) || die "Cannot execute $commandshell\n";
                    print $shell $command;
                    close($shell);
                };
                if( $@ )
                {
                    print STDERR $@;
                }
                chdir($cwd);
            }
            elsif( $command )
            {
                print "Running $command\n" if $verbose;
                my $cwd=getcwd;
                chdir($tgtpath) if $dochdir;
                foreach my $cmdline (split(/\n/,$command) )
                {
                    my @command=split(' ',$cmdline);
                    next if ! @command;
                    next if $command =~ /^\s*\#/;
                    eval
                    {
                        system(@command);
                    };
                    if( $@ )
                    {
                        print STDERR $@;
                    }
                }
                chdir($cwd);
            }
            if( $marker )
            {
                open(my $mf, ">$marker" );
                print $mf $size;
                close($mf);
            }
        }
    }
    if( $bucket && $nfiles > 0 )
    {
        my $error;
        print "Uploading $localpath to S3 ".$bucket->bucket."/".$bucket->prefix."\n" if $verbose;
        $bucket->putDir($localpath,'');
        # keep_root doesn't avoid error trying to delete with cwd as root directory?
        chdir($startdir);
        File::Path::remove_tree($localpath,{keep_root=>1,error=>\$error});
    }
    print STDERR "** Job terminated - maximum run time expired\n" if $expired;
}

# Simplistic parsing of a directory listing.
#
# Assumes that directory and file names do not include space characters!
#
# Returns a list of direcories, and a hash of files keyed on the filename and
# having value the same as the directory entry

sub printExampleConfig
{
    my $started = 0;
    while( my $l = <DATA> )
    {
        $started=1 if $l =~ /^\s*\#/;
        next if ! $started;
        $l =~ s/^\s+//;
        $l = "\n" if $l eq '';
        print $l;
    }
}

#========================================================================

package FtpConnection;

sub new
{
    my ($class, %config) = @_;

    my $self={};
    $self->{verbose}=$config{verbose};
    $self->{remoteuri}=$config{remoteuri};
    $self->{user}=$config{remoteuser};
    $self->{password}=$config{remotepassword};
    $self->{passive}=$config{passiveftp};
    $self->{timeout}=$config{timeout}+0 || 30;
    $self->{pause}=$config{downloadwait}+0 || 1; 
    $self->{reconnectwait}=$config{reconnectwait}+0 || 5;
    $self->{maxreconnect}=$config{maxreconnectiontries}+0 || 5;
    $self->{maxdownloads}=$config{maxdownloadsperconnection}+0 || 5;

    my $remoteuri=$self->{remoteuri};
    my $uri=URI->new($remoteuri);
    die "$remoteuri is not a valid FTP URI.\nMust be an ftp:// URI" if $uri->scheme != 'ftp';

    my $host=$uri->host;
    my $basedir=$uri->path;
    my ($uri_user,$uri_pwd) = split(/\:/,$uri->userinfo,2);

    $self->{host}=$host;
    $self->{user}=$uri_user if $uri_user;
    $self->{password}=$uri_pwd if $uri_pwd;
    $self->{basedir}=$basedir;
    $self->{passive}=$ENV{FTP_PASSIVE} if $self->{passive} eq '';
    $self->{passive}=1 if $self->{passive} eq '';
    $self->{passive} += 0;

    $self->{_ftp} = undef;
    $self->{_dir} = $basedir;
    $self->{_ndownload} = 0;

    return $self=bless $self, $class;
}

sub verbose { return $_[0]->{verbose}; }
sub remoteuri { return $_[0]->{remoteuri}; }
sub host { return $_[0]->{host}; }
sub user { return $_[0]->{user}; }
sub password { return $_[0]->{password}; }
sub passive { return $_[0]->{passive}; }
sub timeout { return $_[0]->{timeout}; }
sub pause { return $_[0]->{pause}; }
sub reconnectwait { return $_[0]->{reconnectwait}; }
sub maxreconnect { return $_[0]->{maxreconnect}; }
sub maxdownloads { return $_[0]->{maxdownloads}; }
sub basedir { return $_[0]->{basedir}; }

sub ftp
{
    my( $self, $force ) = @_;
    return $self->{_ftp} if $self->{_ftp} && ! $force;
    $self->quit;
    my $trying=$self->maxreconnect;
    $trying=1 if $trying < 1;
    my $host=$self->host;
    my $ftp;
    while( $trying-- )
    {
        print "Connecting to $host\n" if $self->verbose;
        $ftp=Net::FTP->new($host, Timeout=>$self->timeout, Passive=>$self->passive );
        last if $ftp;
        Time::HiRes::usleep( $self->reconnectwait * 1000000) if $trying;
    }

    if( ! $ftp )
    {
        die "Cannot make FTP connection to $host\n";
    }

    my $user=$self->user;
    my $password=$self->password;
    my $basedir=$self->basedir;

    $ftp->login($user,$password) || die "Cannot login to $host as $user to $host\n";
    $ftp->binary();
    $ftp->cwd($self->{_dir}) || die "Cannot cd to $basedir on $host\n";
    $self->{_ftp} = $ftp;
    return $ftp;
}

sub quit
{
    my( $self)=@_;
    $self->{_ftp}->quit() if $self->{_ftp};
    $self->{_ftp} = undef;
}

sub reconnect
{
    my( $self)=@_;
    $self->quit;
    Time::HiRes::usleep( $self->reconnectwait * 1000000 );
}

sub run
{
    my( $self, $sub )=@_;
}

sub cwd
{
    my( $self, $dir) = @_;
    $self->{_dir} = $dir;
    return $self->ftp->cwd($dir);
}

sub dirList
{
    my ($self) = @_;
    return $self->parseDir( $self->ftp->dir() );
}

sub get
{
    my ($self,$file,$target) = @_;
    if( $self->maxdownloads > 0 && $self->{_ndownload} >= $self->maxdownloads )
    {
        $self->reconnect;
        $self->{_ndownload} = 0;
    }
    Time::HiRes::usleep( $self->pause * 1000000 ) if $self->{_ndownload};
    my $ntries=0;
    my $success=0;
    while( 1 )
    {

        $success=$self->ftp->get($file,$target);
        last if $success;
        last if $ntries++ >= $self->maxreconnect;
        print "** Download of $file failed - reconnecting\n" if $self->verbose;
        $self->reconnect;
    }
    if( $success )
    {
        $self->{_ndownload}++;
        my $mtime=$self->ftp->mdtm( $file );
        utime $mtime,$mtime,$target if $mtime;
    }
    else
    {
        print "** Download of $file failed\n".$self->ftp->message."\n" 
            if $self->verbose && ! $success;
    }
    return $success;
}

sub parseDir
{
    my($self,@listing)=@_;
    my $dirs=[];
    my $files={};
    @listing=@{$listing[0]} if ref $listing[0];
    foreach my $l (@listing)
    {
        $l =~ s/^\s+//;
        $l =~ s/\s+$//;
        # <DIR> is Microsoft server test
        my $isdir=$l=~/^d/ || $l =~ /\<DIR\>/;
        my $name=(split(' ',$l))[-1];
        # Skip names starting with '.";
        next if $name eq '';
        next if $name =~ /^\./;
        if( $isdir )
        {
            push(@$dirs,$name);
        }
        else
        {
            # Select column based on unix or MS format listing
            my $sizecol =  $l =~ /^\d\d/ ? -2 : 4;
            my $size=(split(' ',$l))[$sizecol];
            $files->{$name}={size=>$size, dir=>$l };
        }
    }
    return $dirs,$files;
}


#========================================================================

package HttpConnection;

use strict;
use Getopt::Std;
use LWP::UserAgent;
use HTTP::Request;
use HTTP::Cookies;
use MIME::Base64;
use Carp;

sub new
{
    my ($class, %config) = @_;

    my $self={};
    $self->{verbose}=$config{verbose};
    $self->{remoteuri}=$config{remoteuri};
    $self->{dirurl}=$config{directorylisturl};
    $self->{dirre}=$config{directorylistre};
    $self->{fileurl}=$config{filelisturl};
    $self->{filere}=$config{filelistre};
    $self->{user}=$config{remoteuser};
    $self->{password}=$config{remotepassword};
    $self->{timeout}=$config{timeout}+0 || 30;

    die "FileListUrl must be defined in configuration\n" if ! $self->{fileurl};
    die "FileListRe must be defined in configuration\n" if ! $self->{filere};

    my $remoteuri=$self->{remoteuri};
    my $uri=URI->new($remoteuri);
    die "$remoteuri is not a valid HTTP URI.\nMust be an http(s):// URI" if $uri->scheme !~ /^https?/;

    my $scheme=$uri->scheme;
    my $host=$uri->host;
    my $basedir=$uri->path;
    my ($uri_user,$uri_pwd) = split(/\:/,$uri->userinfo,2);

    $self->{scheme}=$scheme;
    $self->{host}=$host;
    $self->{user}=$uri_user if $uri_user;
    $self->{password}=$uri_pwd if $uri_pwd;
    $self->{basedir}=$basedir;
    $self->{baseurl}="$scheme://$host";

    $self->{_dir} = $basedir;
    $self->{_ndownload} = 0;

    return $self=bless $self, $class;
}

sub verbose { return $_[0]->{verbose}; }
sub remoteuri { return $_[0]->{remoteuri}; }
sub host { return $_[0]->{host}; }
sub user { return $_[0]->{user}; }
sub password { return $_[0]->{password}; }
sub passive { return $_[0]->{passive}; }
sub timeout { return $_[0]->{timeout}; }
sub pause { return $_[0]->{pause}; }
sub reconnectwait { return $_[0]->{reconnectwait}; }
sub maxreconnect { return $_[0]->{maxreconnect}; }
sub maxdownloads { return $_[0]->{maxdownloads}; }
sub basedir { return $_[0]->{basedir}; }

sub getUserAgent
{
    my($self) = @_;
    if( ! $self->{useragent} )
    {
        my $cookies=HTTP::Cookies->new();
        my $ua=new LWP::UserAgent;
        $ua->env_proxy;
        $ua->cookie_jar($cookies);
        $ua->timeout($self->{timeout});
        $self->{useragent}=$ua;
    }
    return $self->{useragent};
}

sub getUrlContent
{
    my($self,$url)=@_;
    $url=$self->{baseurl}.$url;
    print("Fetching content from $url\n") if $self->{verbose} > 1;

    if( $url ne $self->{cachedurl})
    {
        my $user=$self->{user};
        my $pwd=$self->{password};
        my $ua=$self->getUserAgent();
        my %headers=();
        if( $user )
        {
            $headers{Authorization}="Basic ".encode_base64("$user:$pwd");
        }
        my $response=$ua->get($url,%headers);
        if( $response->code ne '200' )
        {
            die "Cannot retrieve $url: ".$response->message."\n";
        }
        my $content=$response->content;
        if( ! $content )
        {
            die "Cannot retrieve $url: No data\n";
        }
        $self->{cachedurl}=$url;
        $self->{cachedcontent}=$content;
    }
    return $self->{cachedcontent};
}

sub quit
{
}

sub reconnect
{
}

sub run
{
}

sub cwd
{
    my( $self, $dir) = @_;
    $self->{_dir} = $dir;
}

sub dirList
{
    my ($self) = @_;
    print("Fetching directory $self->{_dir}\n") if $self->{verbose} > 1;
    my $curdir=$self->{_dir};
    my $dirs=[];
    my $files={};
    my $dirurl=$self->{dirurl};
    if( $dirurl )
    {
        $dirurl =~ s/\{curdir\}/$curdir/eg;
        my $dirre=$self->{dirre};
        my $dirlist=$self->getUrlContent($dirurl);
        while( $dirlist =~ /$dirre/mg )
        {
            my $name=$+{dirname};
            push(@$dirs,$name) if $name;
        }
    }
    my $fileurl=$self->{fileurl};
    $fileurl =~ s/\{curdir\}/$curdir/eg;
    my $filere=$self->{filere};
    my $filelist=$self->getUrlContent($fileurl);
    while( $filelist =~ /$filere/mg )
    {
        my $name=$+{filename};
        my $size=$+{filesize};
        my $datestr=$+{filedate};
        my $dirline="$name $size $datestr";
        $files->{$name}={size=>$size,dir=>$dirline};
    }
    return $dirs,$files;
}

sub get
{
    my ($self,$file,$target) = @_;
    my $success=0;
    eval
    {
        my $fileurl=$self->{_dir}.'/'.$file;
        my $data=$self->getUrlContent($fileurl);
        open(my $fh,">$target") || die "Cannot open $target";
        binmode($fh);
        print $fh $data;
        close($fh);
        $success=1;
    };
    if( $@ )
    {
        print "** Download of $file failed\n".$@."\n" if $verbose;      
    }
    return $success;
}


#========================================================================

package SmbConnection;

use IPC::Run qw(run);
use LINZ::GNSS::Time qw/datetime_seconds/;


BEGIN
{
    $SmbConnection::smbclient='/usr/bin/smbclient';
}

sub new
{
    my ($class, %config) = @_;

    my $self=bless {}, $class;
    $self->{verbose}=$config{verbose};
    $self->{remoteuri}=$config{remoteuri};
    $self->{user}=$config{remoteuser};
    $self->{password}=$config{remotepassword};
    $self->{timeout}=$config{smbtimeout} || 20;
    $self->{retries}=$config{smbretries} || 3;
    $self->{retrywait}=$config{smbretrywait} || 5;

    my $remoteuri=$self->{remoteuri};

    $remoteuri =~ /^smb:(\/\/[^\/]+\/[^\/]+)(\/.*)?$/ 
        || die "RemoteUri $remoteuri is not a valid samba share smb://host/sharename\n";
    my ($share,$basedir)=($1,$2);

    $self->{share}=$share;
    $self->{basedir}=$basedir;
    $self->{_dir} = $basedir;
    $self->{_dirlist} = {};

    # Haven't got reliable errors from smbclient program, plus seem to get error information
    # in stdout, so do a crude check that there is something in the root directory :-(
    my($in,$out,$err)=$self->_run("dir","*");
    my($dirs,$files)=$self->parseDir($out);
    die "Cannot access samba $remoteuri: $err $out\n"
        if ! @$dirs && ! %$files;
        
    return $self;
}

sub verbose { return $_[0]->{verbose}; }
sub remoteuri { return $_[0]->{remoteuri}; }
sub host { return $_[0]->{host}; }
sub share { return $_[0]->{share}; }
sub user { return $_[0]->{user}; }
sub password { return $_[0]->{password}; }
sub basedir { return $_[0]->{basedir}; }
sub timeout { return $_[0]->{timeout}; }
sub retries { return $_[0]->{retries}; }
sub retrywait { return $_[0]->{retrywait}; }

sub _run
{
    my($self,@smbcommand)=@_;
    my $share = $self->{share};
    my $user=$self->{user};
    my $pwd=$self->{password};
    $pwd=$ENV{PASSWD} if ! $pwd;
    die "Password not defined for samba user $user\n" if ! $pwd;
    my $cmdstr=join(" ",@smbcommand);
    my @command=($SmbConnection::smbclient,'-t',$self->timeout,$share);
    push(@command,$pwd) if $pwd;
    push(@command,'-U',$user,'-c',$cmdstr);
    my $ok = 0;
    my $tries=$self->retries;
    my ($in, $out, $err);
    eval
    {
        while(1) 
        {
            print("Running command: ",join("\n   ",@command),"\n") if $self->verbose > 1;
            $ok=run(\@command,\$in,\$out,\$err);
            print("Samba client error message: $err\n") if $err && $self->verbose;
            print("Output: $out\n") if $self->verbose > 1;
            last if $ok;
            if( $tries-- <= 0 )
            {
                print("smbclient command failed: ".join(" ",@command)) if $self->verbose;
                last;
            }
            print("Retrying smbclient ...") if $self->verbose;
            sleep($self->retrywait);
        };
    };
    if( $@ )
    {
        print("smbclient command failed: $@\n");
        return 0;
    }
    return wantarray ? ($ok,$out,$err) : $ok;
}

sub quit
{
    my( $self)=@_;
}

sub cwd
{
    my( $self, $dir) = @_;
    $self->{_dir} = $dir;
    return 1;
}

sub dirList
{
    my ($self) = @_;
    my $dir=$self->{_dir};
    print("Getting directory of $dir\n") if $self->verbose > 1;
    my($ok,$out,$err) = $self->_run("dir",$dir."/*");
    my($dirs,$files)=$self->parseDir( $out );
    $self->{_dirlist}->{$self->{_dir}}=$files;
    printf("$dir contains: %d directories %d files\n",
        scalar(@$dirs),scalar(keys %$files)) if $self->verbose > 1;
    return $dirs,$files;
}

sub get
{
    my ($self,$file,$target) = @_;
    unlink($target) if -f $target;
    if( -e $target )
    {
        print "Cannot overwrite $target\n";
        return 0;
    }
    my $remote = $self->{_dir}.'/'.$file;
    my($ok,$out,$err) = $self->_run('get',$remote, $target);
    if( ! $ok || ! -f $target )
    {
        if( -f $target ) 
        {
            print("Download $remote returned error status - deleting $target\n");
            unlink($target); 
        }
        return 0;
    }
    my $mtime=$self->{_dirlist}->{$self->{_dir}}->{$file}->{mtime};
    utime $mtime,$mtime,$target if $mtime;
    return 1;
}    

sub parseDir
{
    my($self,$listing)=@_;
    my $dirs=[];
    my $files={};
    foreach my $l (split(/\n/,$listing))
    {
        next if $l !~ /^\s*(\S.*?)\s+([\w])\s+(\d+)\s+(\w\w\w)\s+(\w\w\w)\s+(\d+)\s+(\d\d?\:\d\d\:\d\d)\s+(\d\d\d\d)\s*$/;
        my ($name,$type,$size,$wday,$month,$mday,$time,$year)=($1,$2,$3,$4,$5,$6,$7,$8);
        next if $wday !~ /mon|tue|wed|thu|fri|sat|sun/i;
        my $mon=index('jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec',lc($month));
        next if $mon < 0;
        $mon=int($mon/4)+1;
        my $mtime=datetime_seconds(sprintf("%04d-%02d-%02dT%s",$year,$mon,$mday,$time));
        if( $type eq 'D' )
        {
            print("Found directory $name\n") if $self->verbose > 1;
            push(@$dirs,$name);
        }
        else
        {
            print("Found file $name: $l\n") if $self->verbose > 1;
            # Select column based on unix or MS format listing
            #my $sizecol =  $l =~ /^\d\d/ ? -2 : 4;
            #my $size=(split(' ',$l))[$sizecol];
            $files->{$name}={size=>$size, dir=>$l, mtime=>$mtime };
        }
    }
    return $dirs,$files;
}

#========================================================================
# File connection for testing.

package FileConnection;

use POSIX qw/strftime/;
use File::Copy;
use File::Spec;
use Cwd qw/getcwd/;

sub new
{
    my ($class, %config) = @_;

    my $remoteuri=$config{remoteuri};
    $remoteuri =~ s/^file:(\/\/)?//;

    my $self=bless {cwd=>getcwd, remoteuri=>$remoteuri, _dir=>'' }, $class;
    return $self;
}

sub verbose { return $_[0]->{verbose}; }
sub remoteuri { return $_[0]->{remoteuri}; }
sub host { return $_[0]->{host}; }
sub share { return $_[0]->{share}; }
sub user { return $_[0]->{user}; }
sub password { return $_[0]->{password}; }
sub basedir { return $_[0]->{remoteuri}; }
sub timeout { return $_[0]->{timeout}; }
sub retries { return $_[0]->{retries}; }
sub retrywait { return $_[0]->{retrywait}; }

sub quit
{
    my( $self)=@_;
}

sub cwd
{
    my( $self, $dir) = @_;
    $self->{_dir} = $dir;
    return 1;
}

sub _dirname
{
    my ($self) = @_;
    my $dir=$self->{_dir};
    $dir='.' if $dir eq '';
    $dir = File::Spec->rel2abs($dir,$self->{cwd}) if $dir !~ '^/';
    return $dir;
}

sub dirList
{
    my ($self) = @_;
    my $dir=$self->_dirname;
    print("Getting directory of $dir\n") if $self->verbose > 1;
    my $files={};
    my $dirs=[];
    if( -d $dir && opendir(my $dh, $dir))
    {
        while( my $file=readdir($dh))
        {
            next if $file =~ /^\./;
            my $filepath=$dir.'/'.$file;
            if( -d $filepath )
            {
                push(@$dirs,$file);
            }
            else
            {
                my ($size,$mtime) = (stat($filepath))[7,9];
                my $mdate=POSIX::strftime('%Y-%m-%dT%H:%M:%S',gmtime($mtime));
                my $dir="$file $size $mdate";
                $files->{$file}={size=>$size, dir=>$dir, mtime=>$mdate };
            }
        }
        closedir($dh);
    }
    $self->{_dirlist}->{$self->{_dir}}=$files;
    printf("$dir contains: %d directories %d files\n",
        scalar(@$dirs),scalar(keys %{$files})) if $self->verbose > 1;
    return $dirs,$files;
}

sub get
{
    my ($self,$file,$target) = @_;
    unlink($target) if -f $target;
    if( -e $target )
    {
        print "Cannot overwrite $target\n";
        return 0;
    }
    my $remote = $self->_dirname.'/'.$file;
    return copy($remote,$target);
}    

#========================================================================
__END__

=head2 Example configuration file
 
 # Example configuration file:
 #
 # Note all configuration item values can contain references to other configuration
 # item values as {xxxxx}, where xxx is the other item.  But note special values
 # for date components and file names that should not be used.
 #
 # {xxxx} strings that are not matched can be replaced by environment variables if
 # they exist, except for the code and time patterns listed below, which are 
 # replaced with components of the file path.
 #
 # {ENV:xxx} can be used to explicitly replace environment variables.
 # 
 # {ConfigDir} and {ConfigFile} refer to the directory of this configuration
 # file and the full path of the configuration file.
 #
 # Configuration items can be included from another file using:
 #
 # include filename
 #
 # Filenames are relative to this configuration file.
 
 # RemoteUri is the the base of the remote directory
 
 RemoteUri=ftp://ftp.geonet.org.nz/rawgps
 
 RemoteUser=anonymous
 
 RemotePassword=positionz@linz.govt.nz
 
 TimeOut 30

 # If this is an http or https url then it needs configuration defining how to retrieve 
 # and parse directory and file lists.  The URLs are relative to the base RemoteUri and
 # should include the string {curdir} which will be replaced with the current "directory"
 # being listed. The DirectoryListRe is a regular expression which must include a capture
 # group (?<dirname>...).  The FileListRe is a regular expression that must include  
 # a (?<filename>...) capture group.  Ideally it will also include filesize and filedata
 # capture groups.  Typically the regular expressions will match a line in the content
 # returned by the url, ie something like "^...(?<dirname>...)....$".

 DirectoryListUrl
 DirectoryListRe
 FileListUrl
 FileListRe
 
 # Delay in seconds added after each successful download to be polite to server
 
 DownloadWait 1

 # If a download fails the script will try to reconnect to the server
 # The following options control the reconnection 
 
 MaxReconnectionTries 5

 # Time delay in seconds between reconnection attempts

 ReconnectionWait 5

 # Auto reconnect after specified number of downloads
 
 MaxDownloadsPerConnection 100

 # Maximum runtime in minutes - once this time has expired the job will finish
 
 MaxRunTime 120

 # StatusFile - if this is defined then at the completion of the run there
 # will be a file named either xxx.success or xxx.fail.  The age of this can
 # be tested with the MinTimeSinceLastRun option.  This specifies either a 
 # single time, or two times (since success and since failure).  Time can
 # be followed by h or d for hours or days (eg 5d).  Default is hours.  
 # If the script is run sooner than the minimum time then it will stop 
 # immediately.
 
 # StatusFile .mirror_status
 # MinTimeSinceLastRun 7d 4
 
 # RemoteDir is the path to the files to download.
 #
 # Can include {yyyy},{yy},{mmmm}, {mmm},{mm},{ddd},{dd} which will map to 
 # the corresponding date strings (mmm is 3 letter month name, mmmm is the 
 # full month name). Will also accept Mmm, MMM, Mmmm, MMMM for different 
 # capitalisation.  These can be offset +/- 1 day from the expected day
 # using {xxxx+1} or {xxxx-1}. (Also {xxxx1} is equivalent to {xxxx+1}).

 # Also can accept {code} or {CODE} for upper or lower case four character
 # codes which will match a valid code. Use {Code} for a case insensitive
 # code match.
 # 
 # These will be replaced with values corresponding to the maximum number
 # of days before the current date to process.  Can also include ? for any
 # character, and * for any set of characters.
 
 RemoteDir=/{yyyy}/{ddd}
 
 # RemoteFileRe.  Remote file names are matched against this regular expression.
 # Files that match are candidates for downloading.  
 # This can include any of the time and code components, eg {ddd}. Also it
 # can include regular expression # capture groups (?<xxx>...) to capture 
 # fields that can be used in the target path.  
 
 RemoteFileRe={code}{yyyy}\d{8}[a-z].T02
 
 # Local base directory.  All files downloaded or created by subsequent scripts
 # should be subdirectories of this directory. Use ~ for the directory in which
 # the configuration script is located.  This is not used if the target is an S3
 # bucket.  However the script will create a temporary local directory for retrieving
 # and processing files prior to uploading to S3. 
 #
 # All local filenames below are relative to this (or on S3, relative to the S3 prefix)
 # Post download script are run from this directory unless PostDownloadCommandChDir 
 # is true.
 
 LocalBaseDirectory ~

 # If an S3 bucket is defined then files are installed into the bucket using the 
 # file structure relative to the LocalBaseDirectory.  The file names can be prefixed
 # with a common prefix to generate the corresponding S3 bucket key.  S3 settings
 # are as used by the LINZ::GNSS::AwsS3Bucket module.  

 # s3_bucket my_bucket
 # s3_prefix ${subdir}${subdir?/}

 # Target directory relative to the local base directory.
 # Can include time components
 # as for RemotePath.  Can also include {filename} to use the source filename.
 
 TargetPath={yyyy}/{ddd}/{filename}

 # Marker file.  By default the script checks for the existence of the target 
 # file.  If it exists and is of the correct size it is not downloaded again.  The 
 # script can instead use a marker file defined below.  It it read to determine
 # if the file has been downloaded and the size of the file.

 MarkerPath={yyyy}/{ddd}/{filename}.downloaded

 # Processing script. Command(s) to run once a file has been downloaded.  The script
 # is run in the target directory.  The command can include parameters, and can
 # include the replacement strings for filename, code, etc.
 #
 # If PostDownloadCommandChDir evaluates to true then the script changes to the 
 # download directory to execute the command(s).
 
 PostDownloadCommand process_downloaded_file.sh {filename}
 PostDownloadCommandChDir 1
 
 # Codes to download.  Use Codes * (or omit codes altogether), to download
 # all available codes.
 
 Codes KAIK RGRE
 Codes SCTB
  
 # Codes to discard.  This is applied after codes have been accepted from the Codes list
 # (Though only makes sense if Codes is empty or *).
 
 NotCodes CRUD BAD9
 
 # Number of days before current date to start and end download
 
 StartAge 30
 EndAge 0
